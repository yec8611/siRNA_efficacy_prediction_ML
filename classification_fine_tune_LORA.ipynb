{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from multimolecule import RnaTokenizer, RnaFmModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df = df.drop('inhibition_value', axis=1)\n",
    "df = df.rename(columns={'label_cls': 'inhibition'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"multimolecule/rnafm\"\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 8\n",
    "NUM_FOLDS = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RnaTokenizer.from_pretrained(MODEL_NAME)\n",
    "sep_token = tokenizer.sep_token if tokenizer.sep_token else \"[SEP]\"\n",
    "\n",
    "def combine_sequences(sirna, mrna):\n",
    "    sirna_str = str(sirna)\n",
    "    mrna_str = str(mrna)\n",
    "    return f\"{sirna_str}{sep_token}{mrna_str}\"\n",
    "\n",
    "df['combined_sequence'] = df.apply(lambda row: combine_sequences(row['siRNA_sequence'], row['mRNA_sequence']), axis=1)\n",
    "all_sequences = df['combined_sequence'].tolist()\n",
    "all_labels = df['inhibition'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiRnaClassificationDataset(Dataset):\n",
    "    def __init__(self, sequences, targets, tokenizer, max_len):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = str(self.sequences[idx])\n",
    "        target = int(self.targets[idx])\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sequence, add_special_tokens=True, max_length=self.max_len,\n",
    "            return_token_type_ids=False, padding='max_length', truncation=True,\n",
    "            return_attention_mask=True, return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    if isinstance(model_output, (tuple, list)):\n",
    "        token_embeddings = model_output[0]\n",
    "    else:\n",
    "        token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "pooling_strategy = mean_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_classifier(input_size): return nn.Linear(input_size, 1)\n",
    "def create_medium_mlp_classifier(input_size, hidden_dim=256):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_dim), nn.ReLU(), nn.Dropout(0.1),\n",
    "        nn.Linear(hidden_dim, 1)\n",
    "    )\n",
    "def create_deep_mlp_classifier(input_size, hidden_dims=[512, 256, 128]):\n",
    "    layers = []\n",
    "    current_dim = input_size\n",
    "    for h_dim in hidden_dims:\n",
    "        layers.extend([nn.Linear(current_dim, h_dim), nn.ReLU(), nn.Dropout(0.1)])\n",
    "        current_dim = h_dim\n",
    "    layers.append(nn.Linear(current_dim, 1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.1\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"encoder.layer.0.attention.self.query\", \"encoder.layer.0.attention.self.key\", \"encoder.layer.0.attention.self.value\",\n",
    "    \"encoder.layer.1.attention.self.query\", \"encoder.layer.1.attention.self.key\", \"encoder.layer.1.attention.self.value\",\n",
    "    \"encoder.layer.2.attention.self.query\", \"encoder.layer.2.attention.self.key\", \"encoder.layer.2.attention.self.value\",\n",
    "    \"encoder.layer.3.attention.self.query\", \"encoder.layer.3.attention.self.key\", \"encoder.layer.3.attention.self.value\",\n",
    "    \"encoder.layer.4.attention.self.query\", \"encoder.layer.4.attention.self.key\", \"encoder.layer.4.attention.self.value\",\n",
    "    \"encoder.layer.5.attention.self.query\", \"encoder.layer.5.attention.self.key\", \"encoder.layer.5.attention.self.value\",\n",
    "    \"encoder.layer.6.attention.self.query\", \"encoder.layer.6.attention.self.key\", \"encoder.layer.6.attention.self.value\",\n",
    "    \"encoder.layer.7.attention.self.query\", \"encoder.layer.7.attention.self.key\", \"encoder.layer.7.attention.self.value\",\n",
    "    \"encoder.layer.8.attention.self.query\", \"encoder.layer.8.attention.self.key\", \"encoder.layer.8.attention.self.value\",\n",
    "    \"encoder.layer.9.attention.self.query\", \"encoder.layer.9.attention.self.key\", \"encoder.layer.9.attention.self.value\",\n",
    "    \"encoder.layer.10.attention.self.query\", \"encoder.layer.10.attention.self.key\", \"encoder.layer.10.attention.self.value\",\n",
    "    \"encoder.layer.11.attention.self.query\", \"encoder.layer.11.attention.self.key\", \"encoder.layer.11.attention.self.value\",\n",
    "]\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,\n",
    "    inference_mode=False,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    target_modules=LORA_TARGET_MODULES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnaFmForSequenceClassificationLora(nn.Module):\n",
    "    def __init__(self, model_name, peft_config, head_type='medium', pooling_func=mean_pooling):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.base_model = AutoModel.from_pretrained(model_name)\n",
    "            print(f\"Loaded base model ({model_name}) via AutoModel.\")\n",
    "        except Exception as e:\n",
    "            print(f\"AutoModel failed ({e}), trying RnaFmModel directly...\")\n",
    "            self.base_model = RnaFmModel.from_pretrained(model_name)\n",
    "            print(f\"Loaded base model ({model_name}) via RnaFmModel.\")\n",
    "\n",
    "        self.peft_model = get_peft_model(self.base_model, peft_config)\n",
    "        print(\"PEFT model created. Trainable parameters overview:\")\n",
    "        self.peft_model.print_trainable_parameters()\n",
    "\n",
    "        hidden_size = self.base_model.config.hidden_size\n",
    "        self.pooling = pooling_func\n",
    "\n",
    "        print(f\"Creating classification head of type: {head_type}\")\n",
    "        if head_type == 'simple': self.classifier = create_simple_classifier(hidden_size)\n",
    "        elif head_type == 'medium': self.classifier = create_medium_mlp_classifier(hidden_size)\n",
    "        elif head_type == 'deep': self.classifier = create_deep_mlp_classifier(hidden_size)\n",
    "        else: raise ValueError(\"Invalid head_type.\")\n",
    "\n",
    "        print(\"Model initialization complete.\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.peft_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        pooled_output = self.pooling(outputs, attention_mask)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_lora_model_and_optimizer(model_name, peft_config, head_type, learning_rate, weight_decay):\n",
    "    model = RnaFmForSequenceClassificationLora(model_name, peft_config, head_type=head_type, pooling_func=pooling_strategy)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    print(\"\\nOptimizer initialized for trainable parameters (LoRA + Head).\")\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 10\n",
    "HEAD_TYPE = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_labels, all_predictions, all_probabilities = [], [], []\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            predictions = (probabilities > 0.5).int()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    all_labels, all_predictions, all_probabilities = np.array(all_labels), np.array(all_predictions), np.array(all_probabilities)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary', zero_division=0)\n",
    "    try: roc_auc = roc_auc_score(all_labels, all_probabilities)\n",
    "    except ValueError: roc_auc = float('nan')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return avg_loss, accuracy, precision, recall, f1, roc_auc, all_labels, all_predictions\n",
    "\n",
    "def run_training_fold(model, optimizer, criterion, train_loader, val_loader, epochs, device, fold_num):\n",
    "    best_val_loss = float('inf')\n",
    "    best_adapter_dir = None\n",
    "    best_head_path = None\n",
    "    train_losses, val_losses, metrics_history = [], [], []\n",
    "\n",
    "    fold_save_base = f\"./fold_{fold_num}_best_lora\"\n",
    "    adapter_save_dir = os.path.join(fold_save_base, \"adapter\")\n",
    "    head_save_path = os.path.join(fold_save_base, \"head.pth\")\n",
    "\n",
    "    os.makedirs(adapter_save_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Starting training for Fold {fold_num}, {epochs} epochs...\")\n",
    "    total_fold_start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        avg_train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        avg_val_loss, val_acc, val_prec, val_rec, val_f1, val_auc, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        metrics_history.append({'epoch': epoch + 1, 'train_loss': avg_train_loss, 'val_loss': avg_val_loss,\n",
    "                                'val_accuracy': val_acc, 'val_precision': val_prec, 'val_recall': val_rec,\n",
    "                                'val_f1': val_f1, 'val_roc_auc': val_auc})\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Time: {epoch_time:.2f}s | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            print(f\"  -> New best validation loss: {best_val_loss:.4f}. Saving adapter and head...\")\n",
    "            model.peft_model.save_pretrained(adapter_save_dir)\n",
    "            torch.save(model.classifier.state_dict(), head_save_path)\n",
    "            best_adapter_dir = adapter_save_dir\n",
    "            best_head_path = head_save_path\n",
    "\n",
    "        if device == torch.device(\"mps\"): torch.mps.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    total_fold_time = time.time() - total_fold_start_time\n",
    "    print(f\"\\nTraining finished for Fold {fold_num}. Total time: {total_fold_time:.2f}s\")\n",
    "\n",
    "    return best_adapter_dir, best_head_path, train_losses, val_losses, metrics_history, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "fold_results = []\n",
    "all_metrics_history = []\n",
    "saved_model_paths = []\n",
    "\n",
    "full_dataset = SiRnaClassificationDataset(all_sequences, all_labels, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"\\n--- Starting {NUM_FOLDS}-Fold Cross-Validation with LoRA ---\")\n",
    "cv_start_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(all_sequences)):\n",
    "    fold_num = fold + 1\n",
    "    print(f\"\\n==================== Fold {fold_num}/{NUM_FOLDS} ====================\")\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=0)\n",
    "    val_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=0)\n",
    "    print(f\"Fold {fold_num}: Train samples = {len(train_idx)}, Validation samples = {len(val_idx)}\")\n",
    "\n",
    "    model, optimizer, criterion = initialize_lora_model_and_optimizer(\n",
    "        MODEL_NAME, peft_config, HEAD_TYPE, LEARNING_RATE, WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    best_adapter_dir, best_head_path, train_losses, val_losses, metrics_history, fold_best_val_loss = run_training_fold(\n",
    "        model, optimizer, criterion, train_loader, val_loader, EPOCHS, device, fold_num\n",
    "    )\n",
    "    all_metrics_history.append(metrics_history)\n",
    "    if best_adapter_dir:\n",
    "        saved_model_paths.append(os.path.dirname(best_adapter_dir))\n",
    "\n",
    "    if best_adapter_dir and best_head_path and os.path.exists(best_adapter_dir) and os.path.exists(best_head_path):\n",
    "        print(\"\\nLoading best model state for final evaluation...\")\n",
    "        eval_base_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        eval_peft_model = PeftModel.from_pretrained(eval_base_model, best_adapter_dir, is_trainable=False)\n",
    "        eval_model = nn.Module()\n",
    "        eval_model.peft_model = eval_peft_model\n",
    "        hidden_size = eval_base_model.config.hidden_size\n",
    "        if HEAD_TYPE == 'simple': eval_model.classifier = create_simple_classifier(hidden_size)\n",
    "        elif HEAD_TYPE == 'medium': eval_model.classifier = create_medium_mlp_classifier(hidden_size)\n",
    "        else: eval_model.classifier = create_deep_mlp_classifier(hidden_size)\n",
    "        eval_model.classifier.load_state_dict(torch.load(best_head_path))\n",
    "        eval_model.to(device)\n",
    "        eval_model.eval()\n",
    "\n",
    "        def eval_forward(input_ids, attention_mask):\n",
    "            outputs = eval_model.peft_model(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "            pooled = pooling_strategy(outputs, attention_mask)\n",
    "            logits = eval_model.classifier(pooled)\n",
    "            return logits.squeeze(-1)\n",
    "        eval_model.forward = eval_forward\n",
    "\n",
    "        print(f\"Performing final evaluation for Fold {fold_num}...\")\n",
    "        final_val_loss, final_acc, final_prec, final_rec, final_f1, final_auc, fold_labels, fold_preds = evaluate_model(\n",
    "            eval_model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        print(f\"\\nFold {fold_num} Final Validation Metrics (Best LoRA Model):\")\n",
    "        print(f\"  Loss:      {final_val_loss:.4f}\")\n",
    "        print(f\"  Accuracy:  {final_acc:.4f}\")\n",
    "        print(f\"  Precision: {final_prec:.4f}\")\n",
    "        print(f\"  Recall:    {final_rec:.4f}\")\n",
    "        print(f\"  F1 Score:  {final_f1:.4f}\")\n",
    "        print(f\"  ROC AUC:   {final_auc:.4f}\")\n",
    "\n",
    "        fold_results.append({'fold': fold_num, 'accuracy': final_acc, 'precision': final_prec,\n",
    "                             'recall': final_rec, 'f1': final_f1, 'roc_auc': final_auc,\n",
    "                             'best_val_loss': fold_best_val_loss})\n",
    "        try:\n",
    "            cm = confusion_matrix(fold_labels, fold_preds)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "            disp.plot(cmap=plt.cm.Blues); plt.title(f'Fold {fold_num} - Confusion Matrix (Best LoRA Model)'); plt.show()\n",
    "        except Exception as e: print(f\"Could not display confusion matrix: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nSkipping final evaluation for Fold {fold_num} as best model state was not saved.\")\n",
    "        fold_results.append({'fold': fold_num, 'accuracy': np.nan, 'precision': np.nan,\n",
    "                             'recall': np.nan, 'f1': np.nan, 'roc_auc': np.nan,\n",
    "                             'best_val_loss': np.nan})\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 4)); plt.plot(range(1, EPOCHS + 1), train_losses, label='Training Loss', marker='o'); plt.plot(range(1, EPOCHS + 1), val_losses, label='Validation Loss', marker='x'); plt.xlabel('Epoch'); plt.ylabel('Loss (BCE)'); plt.title(f'Fold {fold_num} - Training & Validation Loss (LoRA)'); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "\n",
    "    print(f\"Cleaning up Fold {fold_num} resources...\")\n",
    "    del model, optimizer, criterion, train_loader, val_loader, train_sampler, val_sampler\n",
    "    if 'eval_model' in locals(): del eval_model\n",
    "    if 'eval_base_model' in locals(): del eval_base_model\n",
    "    if 'eval_peft_model' in locals(): del eval_peft_model\n",
    "    if device == torch.device(\"mps\"): torch.mps.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "cv_end_time = time.time()\n",
    "print(f\"\\n--- LoRA Cross-Validation Finished --- Total Time: {cv_end_time - cv_start_time:.2f}s ---\")\n",
    "\n",
    "print(\"\\nCleaning up saved model directories...\")\n",
    "for path in saved_model_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            shutil.rmtree(path)\n",
    "            print(f\"  Removed: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error removing {path}: {e}\")\n",
    "print(\"Cleanup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n--- LoRA Cross-Validation Summary ---\")\n",
    "print(results_df[[\n",
    "    'fold', 'accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'best_val_loss'\n",
    "]].round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\nAverage Metrics Across Folds (LoRA):\")\n",
    "avg_accuracy = results_df['accuracy'].mean()\n",
    "std_accuracy = results_df['accuracy'].std()\n",
    "avg_precision = results_df['precision'].mean()\n",
    "std_precision = results_df['precision'].std()\n",
    "avg_recall = results_df['recall'].mean()\n",
    "std_recall = results_df['recall'].std()\n",
    "avg_f1 = results_df['f1'].mean()\n",
    "std_f1 = results_df['f1'].std()\n",
    "avg_roc_auc = results_df['roc_auc'].mean()\n",
    "std_roc_auc = results_df['roc_auc'].std()\n",
    "\n",
    "print(f\"  Accuracy:  {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
    "print(f\"  Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
    "print(f\"  Recall:    {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
    "print(f\"  F1 Score:  {avg_f1:.4f} +/- {std_f1:.4f}\")\n",
    "print(f\"  ROC AUC:   {avg_roc_auc:.4f} +/- {std_roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
